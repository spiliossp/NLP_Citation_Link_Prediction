{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "198ce514-f3d5-43a9-9aa3-99d5515b1c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning SPECTER for Citation Link Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bc050fe-89c7-4448-9b08-68a062e8e5e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\NLP\\gnn_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_repo\n",
    "\n",
    "# 1. Φόρτωση abstracts\n",
    "abstracts = pd.read_csv(\n",
    "    r'C:\\Users\\mysmu\\Desktop\\Natural Language Processing\\nlp-cse-uoi-2025\\data_new\\abstracts.txt',\n",
    "    sep=r'\\|\\-\\-\\|', engine='python',\n",
    "    header=None, names=['paper','abstract'], dtype={'paper':int}\n",
    ").fillna('')\n",
    "\n",
    "papers = abstracts['paper'].tolist()\n",
    "docs   = abstracts['abstract'].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d08a58-02d1-4a88-8ae8-86c41c80ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0470cfcb-dfe6-449d-b436-3a6c99353193",
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6216e8e-dccf-4bb6-82ab-aed72b82d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Precompute SPECTER embeddings (pretrained, no fine-tune)\n",
    "model_name = \"allenai/specter\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
    "model      = AutoModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def embed_specter(texts, batch_size=16):\n",
    "    embs = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(batch, padding=True, truncation=True,\n",
    "                        max_length=512, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(**enc).last_hidden_state[:,0]\n",
    "        embs.append(out.cpu().numpy())\n",
    "    return np.vstack(embs)\n",
    "\n",
    "spec_emb = embed_specter(docs, batch_size=16)  # shape (N_papers, 768)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75d0dd58-d477-430a-9c0f-d1c648f08e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for later reuse\n",
    "np.save(r'D:\\NLP\\citation_link_prediction\\specter_pretrained.npy', spec_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d4689-647d-4ced-9428-ebe8d2926826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test specter results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88b54186-b6cb-4720-a646-2d0e4738a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Build paper→index map\n",
    "paper2idx = {p:i for i,p in enumerate(papers)}\n",
    "spec_emb = np.load(r'D:\\NLP\\citation_link_prediction\\specter_pretrained.npy',allow_pickle=True)\n",
    "\n",
    "# 4. Load edge lists\n",
    "train = pd.read_csv(r'D:\\NLP\\citation_link_prediction\\train_edges.csv', dtype=int)\n",
    "val   = pd.read_csv(r'D:\\NLP\\citation_link_prediction\\val_edges.csv',   dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b149064-44dd-4736-a89d-cd2c9d1d1713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         citing   cited  label\n",
      "0        107029   20782      0\n",
      "1          4599  128992      0\n",
      "2          1940   44762      1\n",
      "3          6825   90145      0\n",
      "4          7560   71423      1\n",
      "...         ...     ...    ...\n",
      "1965515   20166   95126      1\n",
      "1965516   32075   31113      0\n",
      "1965517   13248   13231      1\n",
      "1965518   51552   33486      1\n",
      "1965519   12942   19343      1\n",
      "\n",
      "[1965520 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11de987a-407c-4722-aca2-9f1a50740eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Specter feats: 100%|███████████████████████████████████████████████████████| 1965520/1965520 [14:28<00:00, 2263.15it/s]\n",
      "Specter feats: 100%|█████████████████████████████████████████████████████████| 218390/218390 [01:37<00:00, 2230.49it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "# — your existing stuff —\n",
    "paper2idx = {p:i for i,p in enumerate(papers)}\n",
    "spec_emb  = np.load(r'D:\\NLP\\citation_link_prediction\\specter_pretrained.npy', allow_pickle=True)\n",
    "train     = pd.read_csv(r'D:\\NLP\\citation_link_prediction\\train_edges.csv', dtype=int)\n",
    "val       = pd.read_csv(r'D:\\NLP\\citation_link_prediction\\val_edges.csv',   dtype=int)\n",
    "\n",
    "# helper to fetch embeddings\n",
    "def get_emb(paper_id):\n",
    "    idx = paper2idx[paper_id]\n",
    "    return spec_emb[idx]\n",
    "\n",
    "# compute features for a DataFrame (train or val)\n",
    "def add_specter_features(df):\n",
    "    n = len(df)\n",
    "    cos_sims   = np.empty(n, dtype=float)\n",
    "    dots       = np.empty(n, dtype=float)\n",
    "    abs_diffs  = np.empty(n, dtype=float)\n",
    "    \n",
    "    for i, (u, v) in enumerate(tqdm(zip(df['citing'], df['cited']),total=n,desc=\"Specter feats\")):\n",
    "        eu = get_emb(u)\n",
    "        ev = get_emb(v)\n",
    "        \n",
    "        # dot-product\n",
    "        dots[i] = np.dot(eu, ev)\n",
    "        # cosine similarity\n",
    "        cos_sims[i] = cosine_similarity(eu.reshape(1, -1), ev.reshape(1, -1))[0,0]\n",
    "        # L1 (sum of absolute differences)\n",
    "        abs_diffs[i] = np.sum(np.abs(eu - ev))\n",
    "    \n",
    "    df['spec_dot']          = dots\n",
    "    df['spec_cosine_sim']   = cos_sims\n",
    "    df['spec_abs_diff_l1']  = abs_diffs\n",
    "    return df\n",
    "\n",
    "train = add_specter_features(train)\n",
    "val   = add_specter_features(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4745f05-b383-48b7-b80c-55b01e33785a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2dd4163-8720-47c9-a142-f724a2016b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86    109195\n",
      "           1       0.87      0.85      0.86    109195\n",
      "\n",
      "    accuracy                           0.86    218390\n",
      "   macro avg       0.86      0.86      0.86    218390\n",
      "weighted avg       0.86      0.86      0.86    218390\n",
      "\n",
      "Accuracy : 0.8617381748248546\n",
      "ROC AUC  : 0.9331476715379775\n",
      "Log Loss : 0.33054176481348324\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "  'spec_dot',\n",
    "  'spec_cosine_sim',\n",
    "  'spec_abs_diff_l1',\n",
    "]\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train['label']\n",
    "\n",
    "X_val   = val[features]\n",
    "y_val   = val['label']\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, log_loss\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf',    LogisticRegression(\n",
    "                   solver='lbfgs',\n",
    "                   max_iter=1000,   # αύξησε αν δεν συγκρατεί\n",
    "                   class_weight='balanced'  # αν έχεις ανισορροπία κλάσεων\n",
    "               ))\n",
    "])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "\n",
    "# προβλέψεις κατηγορίας\n",
    "y_pred  = pipe.predict(X_val)\n",
    "# προβλεπόμενες πιθανότητες για θετική κλάση\n",
    "y_proba = pipe.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Accuracy :\", accuracy_score(y_val, y_pred))\n",
    "print(\"ROC AUC  :\", roc_auc_score(y_val, y_proba))\n",
    "print(\"Log Loss :\", log_loss(y_val, y_proba))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c86f86e-c5b5-4596-8bee-0f4e02d0a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(r'D:\\NLP\\citation_link_prediction\\train_specter_sim.csv', index=False)\n",
    "val.to_csv(r'D:\\NLP\\citation_link_prediction\\val_specter_sim.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820050d6-029c-4782-9d5a-b4e7505d070c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e413064-99c8-479b-acd6-f7b87e6f3856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fec4b86-8706-4058-be0d-72f60bc433f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722c3949-0c50-46e5-8411-268416c14c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc6cfc-6ff5-4cae-acc0-378e6dac89ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on 768 dims to 98% variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a24e73e-8b85-454f-93a0-7e35be3f0e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Build paper→index map\n",
    "paper2idx = {p:i for i,p in enumerate(papers)}\n",
    "spec_emb = np.load(r'D:\\NLP\\citation_link_prediction\\specter_pretrained.npy',allow_pickle=True)\n",
    "\n",
    "# 4. Load edge lists\n",
    "train = pd.read_csv(r'D:\\NLP\\citation_link_prediction\\train_edges.csv', dtype=int)\n",
    "val   = pd.read_csv(r'D:\\NLP\\citation_link_prediction\\val_edges.csv',   dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "191baf93-e3f7-4740-8eaa-0c6f9b613ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Αρχικός αριθμός διαστάσεων: 768\n",
      "Νέος αριθμός διαστάσεων: 157\n",
      "Συσσωρευμένη διακύμανση με 157 συνιστώσες: 0.9502669807927918\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95, svd_solver='full', whiten=False)  \n",
    "# svd_solver='full' εξασφαλίζει ακριβή υπολογισμό του 98%\n",
    "reduced_emb = pca.fit_transform(spec_emb)\n",
    "\n",
    "print(\"Αρχικός αριθμός διαστάσεων:\", spec_emb.shape[1])\n",
    "print(\"Νέος αριθμός διαστάσεων:\", pca.n_components_)\n",
    "cum_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "print(\"Συσσωρευμένη διακύμανση με\", pca.n_components_, \"συνιστώσες:\", cum_var[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f3dcb93-4302-4212-b846-9916c5b52f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pair_features(u, v):\n",
    "    eu = reduced_emb[paper2idx[u]]\n",
    "    ev = reduced_emb[paper2idx[v]]\n",
    "    return np.hstack([\n",
    "        eu,\n",
    "        ev,\n",
    "        np.abs(eu - ev),   # element‐wise diff\n",
    "        eu * ev            # element‐wise product\n",
    "    ])  # shape = (4 * k,)\n",
    "\n",
    "# apply to each row of train/val\n",
    "X_train = np.vstack([\n",
    "    make_pair_features(u, v)\n",
    "    for u,v in zip(train['citing'], train['cited'])\n",
    "])\n",
    "y_train = train['label'].values\n",
    "\n",
    "X_val   = np.vstack([\n",
    "    make_pair_features(u, v)\n",
    "    for u,v in zip(val['citing'], val['cited'])\n",
    "])\n",
    "y_val   = val['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b567cea9-82a7-4526-bcf9-0f4d6d704324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"new\" 90% Accuracy mlp with embeds hadamard/abs_dif/u/v (best so far 21/5/2025 night ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ea8abd4-94c0-4e48-bacd-eecbbc999baa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.26496088\n",
      "Validation score: 0.897483\n",
      "Iteration 2, loss = 0.25458015\n",
      "Validation score: 0.898897\n",
      "Iteration 3, loss = 0.25029979\n",
      "Validation score: 0.899853\n",
      "Iteration 4, loss = 0.24759928\n",
      "Validation score: 0.900840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\NLP\\gnn_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;mlp&#x27;,\n",
       "                 MLPClassifier(batch_size=16, early_stopping=True,\n",
       "                               hidden_layer_sizes=(256, 128), max_iter=20,\n",
       "                               n_iter_no_change=5, random_state=42,\n",
       "                               verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;mlp&#x27;,\n",
       "                 MLPClassifier(batch_size=16, early_stopping=True,\n",
       "                               hidden_layer_sizes=(256, 128), max_iter=20,\n",
       "                               n_iter_no_change=5, random_state=42,\n",
       "                               verbose=True))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MLPClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(batch_size=16, early_stopping=True, hidden_layer_sizes=(256, 128),\n",
       "              max_iter=20, n_iter_no_change=5, random_state=42, verbose=True)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('mlp',\n",
       "                 MLPClassifier(batch_size=16, early_stopping=True,\n",
       "                               hidden_layer_sizes=(256, 128), max_iter=20,\n",
       "                               n_iter_no_change=5, random_state=42,\n",
       "                               verbose=True))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "mlp_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('mlp',    MLPClassifier(\n",
    "                  hidden_layer_sizes=(256, 128),\n",
    "                  activation='relu',\n",
    "                  alpha=1e-4,            # L2 regularization\n",
    "                  batch_size=16,\n",
    "                  max_iter=20,\n",
    "                  early_stopping=True,\n",
    "                  n_iter_no_change=5,\n",
    "                  random_state=42,\n",
    "                  verbose=True\n",
    "              ))\n",
    "])\n",
    "\n",
    "mlp_pipe.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9f5e05-7e5a-4047-a836-0a52fc5f7294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"new\"  88% Accuracy mlp with abs_diff (embed)/hadamard only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "982e7206-cac5-4561-8b34-c63667dfd8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8844223636613397\n",
      "ROC AUC  : 0.9563316399272859\n",
      "Log Loss : 0.267465022499169\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss\n",
    "\n",
    "y_proba_mlp = mlp_pipe.predict_proba(X_val)[:,1]\n",
    "y_pred_mlp  = mlp_pipe.predict(X_val)\n",
    "\n",
    "print(\"Accuracy :\", accuracy_score(y_val, y_pred_mlp))\n",
    "print(\"ROC AUC  :\", roc_auc_score(y_val, y_proba_mlp))\n",
    "print(\"Log Loss :\", log_loss(y_val, y_proba_mlp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871a7be1-7250-4307-8f41-79252256ddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch for faster training times with GPU/ CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65fd20a9-b961-4e38-a002-cbb4ed04c076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 01 — train loss: 0.2652 — val acc: 0.8921\n",
      "Epoch 02 — train loss: 0.2617 — val acc: 0.8919\n",
      "Epoch 03 — train loss: 0.2613 — val acc: 0.8929\n",
      "Epoch 04 — train loss: 0.2615 — val acc: 0.8898\n",
      "Epoch 05 — train loss: 0.2613 — val acc: 0.8927\n",
      "Epoch 06 — train loss: 0.2613 — val acc: 0.8905\n",
      "Epoch 07 — train loss: 0.2612 — val acc: 0.8918\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 57\u001b[0m\n\u001b[0;32m     55\u001b[0m Xb, yb \u001b[38;5;241m=\u001b[39m X_batch\u001b[38;5;241m.\u001b[39mto(device), y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     56\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 57\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m loss   \u001b[38;5;241m=\u001b[39m criterion(logits, yb)\n\u001b[0;32m     59\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mD:\\NLP\\gnn_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\NLP\\gnn_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[10], line 37\u001b[0m, in \u001b[0;36mCitationMLP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\NLP\\gnn_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\NLP\\gnn_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mD:\\NLP\\gnn_env\\lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mD:\\NLP\\gnn_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\NLP\\gnn_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mD:\\NLP\\gnn_env\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# 1) Προετοιμασία δεδομένων\n",
    "X_train_t = torch.from_numpy(X_train).float()\n",
    "y_train_t = torch.from_numpy(y_train).float()    # float για BCEWithLogitsLoss\n",
    "X_val_t   = torch.from_numpy(X_val).float()\n",
    "y_val_t   = torch.from_numpy(y_val).float()\n",
    "\n",
    "train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "val_ds   = TensorDataset(X_val_t, y_val_t)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "# 2) Συσκευή (GPU αν υπάρχει)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 3) Ορισμός μοντέλου\n",
    "class CitationMLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "           # single logit\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)  # σχήμα [B]\n",
    "\n",
    "model = CitationMLP(X_train.shape[1]).to(device)\n",
    "\n",
    "# 4) Loss & optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# 5) Training loop με verbose & early stopping\n",
    "n_epochs = 20\n",
    "best_val_acc = 0.0\n",
    "patience, counter = 5, 0\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    # --- Training step ---\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for Xb, yb in train_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(Xb)               # [B]\n",
    "        loss   = criterion(logits, yb)   # BCEWithLogitsLoss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * Xb.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    # --- Validation step ---\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in val_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            logits = model(Xb)\n",
    "            probs  = torch.sigmoid(logits)\n",
    "            preds  = (probs > 0.5).long()\n",
    "            correct += (preds == yb.long()).sum().item()\n",
    "            total   += yb.size(0)\n",
    "    val_acc = correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} — train loss: {epoch_loss:.4f} — val acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), \"best_citation_mlp.pt\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# 6) Φόρτωση των καλύτερων βαρών\n",
    "model.load_state_dict(torch.load(\"best_citation_mlp.pt\"))\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a41820b-0964-4ab5-8e8a-532ff89501c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline logistic regression in order to compare results with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1fe8848-5767-4843-8f52-2e953cb79f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\NLP\\gnn_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "# 1. Φόρτωση abstracts\n",
    "abstracts = pd.read_csv(\n",
    "    r'C:\\Users\\mysmu\\Desktop\\Natural Language Processing\\nlp-cse-uoi-2025\\data_new\\abstracts.txt',\n",
    "    sep=r'\\|\\-\\-\\|', engine='python',\n",
    "    header=None, names=['paper','abstract'], dtype={'paper':int}\n",
    ").fillna('')\n",
    "\n",
    "papers = abstracts['paper'].tolist()\n",
    "docs   = abstracts['abstract'].tolist()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
